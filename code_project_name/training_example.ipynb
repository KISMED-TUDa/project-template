{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torchvision.datasets import MNIST\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms.v2 as v2\n",
    "from torchvision.models import resnet18\n",
    "from trainer import GenericTrainer\n",
    "from metrics import accuracy\n",
    "\n",
    "# To open the tensorboard summary run this command in your cmd inside your conda environment : \n",
    "# tensorboard --logdir=xxxx --port=xxxx (Fill in the xxxx, port can be 8080 for example)\n",
    "\n",
    "# Some parameters to be set for training\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "batch_size = 64\n",
    "epochs = 10\n",
    "max_grad_norm = 10\n",
    "\n",
    "# Setup transformations for the inputs and labels\n",
    "transform = v2.Compose([v2.PILToTensor(), v2.ToDtype(torch.float32), v2.Normalize(mean=(33.3285,), std=(78.5655,))]) # MNIST training dataset mean and std\n",
    "target_transform = lambda x:F.one_hot(torch.tensor(x), num_classes=10).float()\n",
    "\n",
    "# Setup the dataset and dataloaders\n",
    "training_dataset = MNIST(root=r\"../data/raw\", train=True, download=True, transform=transform, target_transform=target_transform)\n",
    "training_loader = DataLoader(dataset=training_dataset, batch_size=batch_size, shuffle=True, pin_memory=True)\n",
    "\n",
    "val_dataset = MNIST(root=r\"../data/raw\", train=False, download=True, transform=transform, target_transform=target_transform)\n",
    "val_loader = DataLoader(dataset=val_dataset, batch_size=batch_size, shuffle=True, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import MIMOModel\n",
    "# Setup the model and change its input channels from 3 (RGB) to 1 (Grayscale)\n",
    "# Typical resnet18\n",
    "model = resnet18(num_classes=10)\n",
    "model.conv1 = torch.nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False) # There is unfortunately no external way to change the input channel size\n",
    "model = model.to(device)\n",
    "\n",
    "# MIMO resnet18\n",
    "model = resnet18(num_classes=10)\n",
    "model.conv1 = torch.nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False) # There is unfortunately no external way to change the input channel size\n",
    "model = model.to(device)\n",
    "\n",
    "# Setup optimizer and scheduler\n",
    "optimizer = torch.optim.SGD(params=model.parameters(), lr=1e-2, momentum=0.9)\n",
    "scheduler = torch.optim.lr_scheduler.ConstantLR(optimizer=optimizer, factor=1., total_iters=epochs)\n",
    "\n",
    "# Setup loss and metrics\n",
    "loss = torch.nn.CrossEntropyLoss()\n",
    "metrics = {\"Accuracy\" : accuracy}\n",
    "\n",
    "# Setup the trainer and train\n",
    "trainer = GenericTrainer(device=device, model=model, loss=loss, metrics=metrics, optimizer=optimizer, scheduler=scheduler, \n",
    "                        max_grad_norm=max_grad_norm, fp16_precision=True, log_every_n_steps=25, save_every_n_epochs=5, \n",
    "                        epochs=epochs, seed=42, verbose=True)\n",
    "trainer.train(training_loader, val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haida\\AppData\\Local\\Temp\\ipykernel_23984\\3188810459.py:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(path_to_model) # Load the checkpoint\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision.models import resnet18\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "path_to_model = r\"runs\\Nov21_09-21-56_Work_PC_Jad\\checkpoint_00010.pt\" # Example path, replace with your own\n",
    "checkpoint = torch.load(path_to_model) # Load the checkpoint\n",
    "\n",
    "# Setup the model and change its input channels from 3 (RGB) to 1 (Grayscale)\n",
    "model = resnet18(num_classes=10)\n",
    "model.conv1 = torch.nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False) # There is unfortunately no external way to change the input channel size\n",
    "model.load_state_dict(checkpoint[\"state_dict\"]) # Load the model weights into the newly initialized model\n",
    "model = model.to(device)\n",
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label : tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]), argmax: 8\n",
      "Prediction : [7.51e-14 6.35e-13 1.40e-13 7.25e-12 2.24e-12 1.09e-09 2.14e-11 1.87e-13\n",
      " 1.00e+00 6.76e-13], argmax: 8\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "idx = 125\n",
    "image, label = training_dataset[idx]\n",
    "with torch.no_grad():\n",
    "    prediction = torch.softmax(model(image.to(device).unsqueeze(0)), dim=-1).cpu().numpy()\n",
    "\n",
    "plt.imshow(image.numpy().squeeze())\n",
    "plt.show()\n",
    "print(f\"Label : {label}, argmax: {label.argmax(dim=-1)}\\nPrediction : {prediction.flatten()}, argmax: {prediction.argmax(axis=-1)[0]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "raman_unmixing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
